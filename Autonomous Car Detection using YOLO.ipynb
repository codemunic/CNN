{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "import scipy.io\n",
    "import scipy.misc\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to filter with threshold on class scores\n",
    "def yolo_filter_boxes(box_confidence, boxes, box_class_probs, threshold = .6):\n",
    "    \"\"\"Filters YOLO boxes by thresholding on object and class confidence.\n",
    "    \n",
    "    Arguments:\n",
    "    box_confidence -- tensor of shape (19, 19, 5, 1)\n",
    "    boxes -- tensor of shape (19, 19, 5, 4)\n",
    "    box_class_probs -- tensor of shape (19, 19, 5, 80)\n",
    "    threshold -- real value, if [ highest class probability score < threshold], then get rid of the corresponding box\n",
    "    \n",
    "    Returns:\n",
    "    scores -- tensor of shape (None,), containing the class probability score for selected boxes\n",
    "    boxes -- tensor of shape (None, 4), containing (b_x, b_y, b_h, b_w) coordinates of selected boxes\n",
    "    classes -- tensor of shape (None,), containing the index of the class detected by the selected boxes\n",
    "    \n",
    "    Note: \"None\" is here because you don't know the exact number of selected boxes, as it depends on the threshold. \n",
    "    For example, the actual output size of scores would be (10,) if there are 10 boxes.\n",
    "    \"\"\"\n",
    "    box_scores=box_confidence*box_class_probs #(19,19,5,80)\n",
    "    \n",
    "    # Get argmax and max scores for each box\n",
    "    box_classes=K.argmax(box_scores,axis=-1)\n",
    "    box_class_scores=K.max(box_scores,axis=-1)\n",
    "    \n",
    "    # Create a boolean mask\n",
    "    filtering_mask=box_class_scores>=threshold\n",
    "    \n",
    "    # filter out all that has more class scores than threshold\n",
    "    scores=tf.boolean_mask(box_classes_scores,filtering_mask)  #(None,)\n",
    "    boxes=tf.boolean_mask(boxes,filtering_mask)            #(None,4)\n",
    "    classes=tf.boolean_mask(box_classes,filtering_mask)    #(None,)\n",
    "    \n",
    "    return scores,boxes,classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate intersection over union\n",
    "def iou(box1, box2):\n",
    "    \"\"\"Implement the intersection over union (IoU) between box1 and box2\n",
    "    \n",
    "    Arguments:\n",
    "    box1 -- first box, list object with coordinates (x1, y1, x2, y2)\n",
    "    box2 -- second box, list object with coordinates (x1, y1, x2, y2)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Calculate intersection area\n",
    "    xi1 = max(box1[0],box2[0])\n",
    "    yi1 = max(box1[1],box2[1])\n",
    "    xi2 = min(box1[2],box2[2])\n",
    "    yi2 = min(box1[3],box2[3])\n",
    "    inter_area = max(xi2-xi1,0)*max(yi2-yi1,0)\n",
    "    \n",
    "    #Calculate union area\n",
    "    box1_area = (box1[2]-box1[0])*(box1[3]-box1[1])\n",
    "    box2_area = (box2[2]-box2[0])*(box2[3]-box2[1])\n",
    "    union_area = box1_area+box2_area-inter_area\n",
    "    \n",
    "    iou = inter_area/union_area\n",
    "    \n",
    "    return iou\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yolo_non_max_suppression(scores, boxes, classes, max_boxes = 10, iou_threshold = 0.5):\n",
    "    \"\"\"\n",
    "    Applies Non-max suppression (NMS) to set of boxes\n",
    "    \n",
    "    Arguments:\n",
    "    scores -- tensor of shape (None,), output of yolo_filter_boxes()\n",
    "    boxes -- tensor of shape (None, 4), output of yolo_filter_boxes() that have been scaled to the image size (see later)\n",
    "    classes -- tensor of shape (None,), output of yolo_filter_boxes()\n",
    "    max_boxes -- integer, maximum number of predicted boxes you'd like\n",
    "    iou_threshold -- real value, \"intersection over union\" threshold used for NMS filtering\n",
    "    \n",
    "    Returns:\n",
    "    scores -- tensor of shape (, None), predicted score for each box\n",
    "    boxes -- tensor of shape (4, None), predicted box coordinates\n",
    "    classes -- tensor of shape (, None), predicted class for each box\n",
    "    \n",
    "    Note: The \"None\" dimension of the output tensors has obviously to be less than max_boxes. Note also that this\n",
    "    function will transpose the shapes of scores, boxes, classes. This is made for convenience.\n",
    "    \"\"\"\n",
    "    \n",
    "    max_boxes_tensor = K.variable(max_boxes, dtype='int32')     # tensor to be used in tf.image.non_max_suppression()\n",
    "    K.get_session().run(tf.variables_initializer([max_boxes_tensor])) # initialize variable max_boxes_tensor\n",
    "    \n",
    "    # Use tf.image.non_max_suppression() to get the list of indices corresponding to boxes you keep\n",
    "    nms_indices = tf.image.non_max_suppression(boxes,scores,max_boxes,iou_threshold)\n",
    "    \n",
    "    scores=K.gather(scores,nms_indices)  #(10,)\n",
    "    boxes=K.gather(scores,nms_indices)   #(10,4)\n",
    "    classes=K.gather(classes,nms_indices) #(10,)\n",
    "    \n",
    "    return scores,boxes,classes\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yolo_boxes_to_corners(box_xy, box_wh):\n",
    "    \"\"\"Convert YOLO box predictions to bounding box corners.\"\"\"\n",
    "    box_mins = box_xy - (box_wh / 2.)\n",
    "    box_maxes = box_xy + (box_wh / 2.)\n",
    "\n",
    "    return K.concatenate([\n",
    "        box_mins[..., 1:2],  # y_min\n",
    "        box_mins[..., 0:1],  # x_min\n",
    "        box_maxes[..., 1:2],  # y_max\n",
    "        box_maxes[..., 0:1]  # x_max\n",
    "    ])\n",
    "\n",
    "def scale_boxes(boxes, image_shape):\n",
    "    \"\"\" Scales the predicted boxes in order to be drawable on the image\"\"\"\n",
    "    height = image_shape[0]\n",
    "    width = image_shape[1]\n",
    "    image_dims = K.stack([height, width, height, width])\n",
    "    image_dims = K.reshape(image_dims, [1, 4])\n",
    "    boxes = boxes * image_dims\n",
    "    return boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yolo_eval(yolo_outputs, image_shape = (720., 1280.), max_boxes=10, score_threshold=.6, iou_threshold=.5):\n",
    "    \"\"\"\n",
    "    Converts the output of YOLO encoding (a lot of boxes) to your predicted boxes along with their scores, box coordinates and classes.\n",
    "    \n",
    "    Arguments:\n",
    "    yolo_outputs -- output of the encoding model (for image_shape of (608, 608, 3)), contains 4 tensors:\n",
    "                    box_confidence: tensor of shape (None, 19, 19, 5, 1)\n",
    "                    box_xy: tensor of shape (None, 19, 19, 5, 2)\n",
    "                    box_wh: tensor of shape (None, 19, 19, 5, 2)\n",
    "                    box_class_probs: tensor of shape (None, 19, 19, 5, 80)\n",
    "    image_shape -- tensor of shape (2,) containing the input shape, in this notebook we use (608., 608.) (has to be float32 dtype)\n",
    "    max_boxes -- integer, maximum number of predicted boxes you'd like\n",
    "    score_threshold -- real value, if [ highest class probability score < threshold], then get rid of the corresponding box\n",
    "    iou_threshold -- real value, \"intersection over union\" threshold used for NMS filtering\n",
    "    \n",
    "    Returns:\n",
    "    scores -- tensor of shape (None, ), predicted score for each box\n",
    "    boxes -- tensor of shape (None, 4), predicted box coordinates\n",
    "    classes -- tensor of shape (None,), predicted class for each box\n",
    "    \"\"\"\n",
    "    \n",
    "    box_confidence, box_xy, box_wh, box_class_probs = yolo_outputs\n",
    "    \n",
    "    # Convert boxes to be ready for filtering functions\n",
    "    boxes = yolo_boxes_to_corners(box_xy, box_wh)\n",
    "    \n",
    "    scores, boxes, classes = yolo_filter_boxes(box_confidence, boxes, box_class_probs, threshold = score_threshold)\n",
    "    \n",
    "    # Scale boxes back to original image shape.YOLO's network was trained to run on 608x608 images. \n",
    "    # If you are testing this data on a different size image--for example, the car detection dataset had \n",
    "    # 720x1280 images--this step rescales the boxes so that they can be plotted on top of the original \n",
    "    # 720x1280 image.\n",
    "    \n",
    "    boxes = scale_boxes(boxes, image_shape)\n",
    "    \n",
    "    scores, boxes, classes = yolo_non_max_suppression(scores, boxes, classes, max_boxes = max_boxes, iou_threshold = iou_threshold)\n",
    "    \n",
    "    return scores, boxes, classes\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_classes(classes_path):\n",
    "    with open(classes_path) as f:\n",
    "        class_names = f.readlines()\n",
    "    class_names = [c.strip() for c in class_names]\n",
    "    return class_names\n",
    "\n",
    "def read_anchors(anchors_path):\n",
    "    with open(anchors_path) as f:\n",
    "        anchors = f.readline()\n",
    "        anchors = [float(x) for x in anchors.split(',')]\n",
    "        anchors = np.array(anchors).reshape(-1, 2)\n",
    "    return anchors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = K.get_session()\n",
    "class_names = read_classes(\"model_data/coco_classes.txt\")\n",
    "anchors = read_anchors(\"model_data/yolo_anchors.txt\")\n",
    "image_shape = (720., 1280.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "# These weights come from the official YOLO website, and were converted using a function written by Allan Zelener.\n",
    "# Load pretrained yolo model\n",
    "yolo_model = load_model(\"yolo.h5\")\n",
    "\n",
    "# This model converts a preprocessed batch of input images (shape: (m, 608, 608, 3)) \n",
    "# into a tensor of shape (m, 19, 19, 5, 85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The output of yolo_model is a (m, 19, 19, 5, 85) tensor \n",
    "# that needs to pass through non-trivial processing and conversion.\n",
    "\n",
    "def yolo_head(feats, anchors, num_classes):\n",
    "    \"\"\"Convert final layer features to bounding box parameters.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    feats : tensor\n",
    "        Final convolutional layer features.\n",
    "    anchors : array-like\n",
    "        Anchor box widths and heights.\n",
    "    num_classes : int\n",
    "        Number of target classes.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    box_xy : tensor\n",
    "        x, y box predictions adjusted by spatial location in conv layer.\n",
    "    box_wh : tensor\n",
    "        w, h box predictions adjusted by anchors and conv spatial resolution.\n",
    "    box_conf : tensor\n",
    "        Probability estimate for whether each box contains any object.\n",
    "    box_class_pred : tensor\n",
    "        Probability distribution estimate for each box over class labels.\n",
    "    \"\"\"\n",
    "    num_anchors = len(anchors)\n",
    "    # Reshape to batch, height, width, num_anchors, box_params.\n",
    "    anchors_tensor = K.reshape(K.variable(anchors), [1, 1, 1, num_anchors, 2])\n",
    "    # Static implementation for fixed models.\n",
    "    # TODO: Remove or add option for static implementation.\n",
    "    # _, conv_height, conv_width, _ = K.int_shape(feats)\n",
    "    # conv_dims = K.variable([conv_width, conv_height])\n",
    "\n",
    "    # Dynamic implementation of conv dims for fully convolutional model.\n",
    "    conv_dims = K.shape(feats)[1:3]  # assuming channels last\n",
    "    # In YOLO the height index is the inner most iteration.\n",
    "    conv_height_index = K.arange(0, stop=conv_dims[0])\n",
    "    conv_width_index = K.arange(0, stop=conv_dims[1])\n",
    "    conv_height_index = K.tile(conv_height_index, [conv_dims[1]])\n",
    "\n",
    "    # TODO: Repeat_elements and tf.split doesn't support dynamic splits.\n",
    "    # conv_width_index = K.repeat_elements(conv_width_index, conv_dims[1], axis=0)\n",
    "    conv_width_index = K.tile(K.expand_dims(conv_width_index, 0), [conv_dims[0], 1])\n",
    "    conv_width_index = K.flatten(K.transpose(conv_width_index))\n",
    "    conv_index = K.transpose(K.stack([conv_height_index, conv_width_index]))\n",
    "    conv_index = K.reshape(conv_index, [1, conv_dims[0], conv_dims[1], 1, 2])\n",
    "    conv_index = K.cast(conv_index, K.dtype(feats))\n",
    "    \n",
    "    feats = K.reshape(feats, [-1, conv_dims[0], conv_dims[1], num_anchors, num_classes + 5])\n",
    "    conv_dims = K.cast(K.reshape(conv_dims, [1, 1, 1, 1, 2]), K.dtype(feats))\n",
    "\n",
    "    # Static generation of conv_index:\n",
    "    # conv_index = np.array([_ for _ in np.ndindex(conv_width, conv_height)])\n",
    "    # conv_index = conv_index[:, [1, 0]]  # swap columns for YOLO ordering.\n",
    "    # conv_index = K.variable(\n",
    "    #     conv_index.reshape(1, conv_height, conv_width, 1, 2))\n",
    "    # feats = Reshape(\n",
    "    #     (conv_dims[0], conv_dims[1], num_anchors, num_classes + 5))(feats)\n",
    "\n",
    "    box_confidence = K.sigmoid(feats[..., 4:5])\n",
    "    box_xy = K.sigmoid(feats[..., :2])\n",
    "    box_wh = K.exp(feats[..., 2:4])\n",
    "    box_class_probs = K.softmax(feats[..., 5:])\n",
    "\n",
    "    # Adjust preditions to each spatial grid point and anchor size.\n",
    "    # Note: YOLO iterates over height index before width index.\n",
    "    box_xy = (box_xy + conv_index) / conv_dims\n",
    "    box_wh = box_wh * anchors_tensor / conv_dims\n",
    "\n",
    "    return box_confidence, box_xy, box_wh, box_class_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo_outputs = yolo_head(yolo_model.output, anchors, len(class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yolo_eval(yolo_outputs,\n",
    "              image_shape,\n",
    "              max_boxes=10,\n",
    "              score_threshold=.6,\n",
    "              iou_threshold=.5):\n",
    "    \"\"\"Evaluate YOLO model on given input batch and return filtered boxes.\"\"\"\n",
    "    box_confidence, box_xy, box_wh, box_class_probs = yolo_outputs\n",
    "    boxes = yolo_boxes_to_corners(box_xy, box_wh)\n",
    "    boxes, scores, classes = yolo_filter_boxes(\n",
    "        box_confidence, boxes, box_class_probs, threshold=score_threshold)\n",
    "    \n",
    "    # Scale boxes back to original image shape.\n",
    "    height = image_shape[0]\n",
    "    width = image_shape[1]\n",
    "    image_dims = K.stack([height, width, height, width])\n",
    "    image_dims = K.reshape(image_dims, [1, 4])\n",
    "    boxes = boxes * image_dims\n",
    "\n",
    "    # TODO: Something must be done about this ugly hack!\n",
    "    max_boxes_tensor = K.variable(max_boxes, dtype='int32')\n",
    "    K.get_session().run(tf.variables_initializer([max_boxes_tensor]))\n",
    "    nms_index = tf.image.non_max_suppression(\n",
    "        boxes, scores, max_boxes_tensor, iou_threshold=iou_threshold)\n",
    "    boxes = K.gather(boxes, nms_index)\n",
    "    scores = K.gather(scores, nms_index)\n",
    "    classes = K.gather(classes, nms_index)\n",
    "    \n",
    "    return boxes, scores, classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores, boxes, classes = yolo_eval(yolo_outputs, image_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(img_path, model_image_size):\n",
    "    image_type = imghdr.what(img_path)\n",
    "    image = Image.open(img_path)\n",
    "    resized_image = image.resize(tuple(reversed(model_image_size)), Image.BICUBIC)\n",
    "    image_data = np.array(resized_image, dtype='float32')\n",
    "    image_data /= 255.\n",
    "    image_data = np.expand_dims(image_data, 0)  # Add batch dimension.\n",
    "    return image, image_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_colors(class_names):\n",
    "    hsv_tuples = [(x / len(class_names), 1., 1.) for x in range(len(class_names))]\n",
    "    colors = list(map(lambda x: colorsys.hsv_to_rgb(*x), hsv_tuples))\n",
    "    colors = list(map(lambda x: (int(x[0] * 255), int(x[1] * 255), int(x[2] * 255)), colors))\n",
    "    random.seed(10101)  # Fixed seed for consistent colors across runs.\n",
    "    random.shuffle(colors)  # Shuffle colors to decorrelate adjacent classes.\n",
    "    random.seed(None)  # Reset seed to default.\n",
    "    return colors\n",
    "\n",
    "def draw_boxes(image, out_scores, out_boxes, out_classes, class_names, colors):\n",
    "    \n",
    "    font = ImageFont.truetype(font='font/FiraMono-Medium.otf',size=np.floor(3e-2 * image.size[1] + 0.5).astype('int32'))\n",
    "    thickness = (image.size[0] + image.size[1]) // 300\n",
    "\n",
    "    for i, c in reversed(list(enumerate(out_classes))):\n",
    "        predicted_class = class_names[c]\n",
    "        box = out_boxes[i]\n",
    "        score = out_scores[i]\n",
    "\n",
    "        label = '{} {:.2f}'.format(predicted_class, score)\n",
    "\n",
    "        draw = ImageDraw.Draw(image)\n",
    "        label_size = draw.textsize(label, font)\n",
    "\n",
    "        top, left, bottom, right = box\n",
    "        top = max(0, np.floor(top + 0.5).astype('int32'))\n",
    "        left = max(0, np.floor(left + 0.5).astype('int32'))\n",
    "        bottom = min(image.size[1], np.floor(bottom + 0.5).astype('int32'))\n",
    "        right = min(image.size[0], np.floor(right + 0.5).astype('int32'))\n",
    "        print(label, (left, top), (right, bottom))\n",
    "\n",
    "        if top - label_size[1] >= 0:\n",
    "            text_origin = np.array([left, top - label_size[1]])\n",
    "        else:\n",
    "            text_origin = np.array([left, top + 1])\n",
    "\n",
    "        # My kingdom for a good redistributable image drawing library.\n",
    "        for i in range(thickness):\n",
    "            draw.rectangle([left + i, top + i, right - i, bottom - i], outline=colors[c])\n",
    "        draw.rectangle([tuple(text_origin), tuple(text_origin + label_size)], fill=colors[c])\n",
    "        draw.text(text_origin, label, fill=(0, 0, 0), font=font)\n",
    "        del draw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(sess, image_file):\n",
    "    \"\"\"\n",
    "    Runs the graph stored in \"sess\" to predict boxes for \"image_file\". Prints and plots the preditions.\n",
    "    \n",
    "    Arguments:\n",
    "    sess -- your tensorflow/Keras session containing the YOLO graph\n",
    "    image_file -- name of an image stored in the \"images\" folder.\n",
    "    \n",
    "    Returns:\n",
    "    out_scores -- tensor of shape (None, ), scores of the predicted boxes\n",
    "    out_boxes -- tensor of shape (None, 4), coordinates of the predicted boxes\n",
    "    out_classes -- tensor of shape (None, ), class index of the predicted boxes\n",
    "    \n",
    "    Note: \"None\" actually represents the number of predicted boxes, it varies between 0 and max_boxes. \n",
    "    \"\"\"\n",
    "\n",
    "    # Preprocess your image\n",
    "    image, image_data = preprocess_image(\"images/\" + image_file, model_image_size = (608, 608))\n",
    "\n",
    "    # Run the session with the correct tensors and choose the correct placeholders in the feed_dict.\n",
    "    # You'll need to use feed_dict={yolo_model.input: ... , K.learning_phase(): 0})\n",
    "    \n",
    "    out_scores, out_boxes, out_classes = None\n",
    "\n",
    "    # Print predictions info\n",
    "    print('Found {} boxes for {}'.format(len(out_boxes), image_file))\n",
    "    # Generate colors for drawing bounding boxes.\n",
    "    colors = generate_colors(class_names)\n",
    "    # Draw bounding boxes on the image file\n",
    "    draw_boxes(image, out_scores, out_boxes, out_classes, class_names, colors)\n",
    "    # Save the predicted bounding box on the image\n",
    "    image.save(os.path.join(\"out\", image_file), quality=90)\n",
    "    # Display the results in the notebook\n",
    "    output_image = scipy.misc.imread(os.path.join(\"out\", image_file))\n",
    "    imshow(output_image)\n",
    "    \n",
    "    return out_scores, out_boxes, out_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_scores, out_boxes, out_classes = predict(sess, \"test.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
